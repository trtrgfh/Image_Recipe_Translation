{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663cef75-121b-4a2a-adb8-7ae2caa75760",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import vit_b_16, vit_b_32, mobilenet_v2, resnet18, alexnet, vgg16\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a6502b-8545-4947-a080-8cda4f14263b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "print(f\"device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8807a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "topicModel='LDA'\n",
    "nClasses = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7335b534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = np.load('LDA_dataset.npy')\n",
    "# # dataset = np.load('NMF_dataset.npy')\n",
    "# train_dataset, test_dataset = train_test_split(dataset, train_size=0.85 , random_state=42)\n",
    "# train_dataset, val_dataset = train_test_split(train_dataset, train_size=0.8 , random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649807ab-07e2-4fc9-9e90-23fa07840a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # def load_dataset(topicModel): # 'LDA' or 'NMF'\n",
    "# #     dataset = np.load(topicModel + '_dataset.npy').tolist()\n",
    "# def load_dataset(dataset):\n",
    "#     dataset = dataset.tolist()\n",
    "#     for i in range(len(dataset)):\n",
    "#         if (i+1) % 100 == 0:\n",
    "#             print('loading image {} of {}'.format(i+1, len(dataset)))\n",
    "#         image = Image.open(dataset[i][0])\n",
    "#         image = image.resize((224, 224))  # Resize image to 112x112 (adjust as needed)\n",
    "#         image = image.convert('RGB')\n",
    "#         image = np.array(image)\n",
    "#         image = np.transpose(image, (2, 0, 1))\n",
    "#         image = image / 255.0\n",
    "#         image_tensor = torch.tensor(image, dtype=torch.float32)\n",
    "#         dataset[i].append(image_tensor)\n",
    "#     return dataset        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ce4a1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train_dataset = load_dataset(train_dataset)\n",
    "# val_dataset = load_dataset(val_dataset)\n",
    "# test_dataset = load_dataset(test_dataset)\n",
    "\n",
    "# with open(f'./{topicModel}_train.pkl', 'wb') as f:\n",
    "#         pickle.dump(train_dataset, f)\n",
    "# with open(f'./{topicModel}_val.pkl', 'wb') as f:\n",
    "#         pickle.dump(val_dataset, f)\n",
    "# with open(f'./{topicModel}_test.pkl', 'wb') as f:\n",
    "#         pickle.dump(test_dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756429ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./data/processed/{topicModel}_train.pkl', 'rb') as f:\n",
    "    train_dataset = pickle.load(f) \n",
    "with open(f'./data/processed/{topicModel}_val.pkl', 'rb') as f:\n",
    "    val_dataset = pickle.load(f) \n",
    "with open(f'./data/processed/{topicModel}_test.pkl', 'rb') as f:\n",
    "    test_dataset = pickle.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c843eb4-c409-40e5-9d40-7661781191a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_array, transform=None):\n",
    "        self.data_array = data_array\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_array)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path, label, image = self.data_array[index]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if isinstance(label, str):\n",
    "            label = int(label)\n",
    "        \n",
    "        return image_path, label, image\n",
    "    \n",
    "# transform = transforms.Compose([\n",
    "#     transforms.Resize((224, 224)),\n",
    "# ])\n",
    "\n",
    "train_dataset = CustomDataset(train_dataset, transform=None)\n",
    "val_dataset = CustomDataset(val_dataset, transform=None)\n",
    "test_dataset = CustomDataset(test_dataset, transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2da047f-f552-49ad-95d7-6dd21241c9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataset), len(val_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6feafdfb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def new_vit_b_16(nClasses, device):\n",
    "    model = vit_b_16(weights='IMAGENET1K_V1')\n",
    "#     model = vit_b_16(weights=None)\n",
    "\n",
    "#     for name, param in model.named_parameters():\n",
    "#         if 'encoder_layer_11' in name:\n",
    "#             param.require_grad=True\n",
    "#         else:\n",
    "#             param.require_grad=False\n",
    "                \n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    num_features = model.heads.head.in_features\n",
    "    model.heads.head = torch.nn.Linear(num_features, nClasses)\n",
    "    model = model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2e88bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_mobilenet_v2(nClasses, device):\n",
    "    model = mobilenet_v2(weights=None)\n",
    "    num_features = model.classifier[1].in_features\n",
    "    model.classifier[1] = torch.nn.Linear(num_features, nClasses)\n",
    "    model = model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf05843",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def new_resnet18(nClasses, device):\n",
    "    model = resnet18(weights='IMAGENET1K_V1')\n",
    "    # for param in model.parameters():\n",
    "    #     param.requires_grad = False\n",
    "    \n",
    "    for name, child in model.named_children():\n",
    "        if name in ['layer4']:  \n",
    "            for param in child.parameters():\n",
    "                param.requires_grad = True\n",
    "        else:\n",
    "            for param in child.parameters():\n",
    "                param.requires_grad = False\n",
    "            \n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = torch.nn.Linear(num_features, nClasses)\n",
    "    model = model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f661c2e2-0775-490c-bbe0-74d165b5a9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_alexnet(nClasses, device):\n",
    "    model = alexnet(weights='IMAGENET1K_V1')\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    # model.classifier[4] = torch.nn.Linear(4096, 4096)\n",
    "    num_features = model.classifier[6].in_features\n",
    "    model.classifier[6] = torch.nn.Linear(num_features, nClasses)\n",
    "    model = model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e2a7a9-4e79-46ec-bd47-226362f1bd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = new_vit_b_16(nClasses, device)\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d72bd8-27e0-46f6-aa53-3fbd122c8453",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_vgg16(nClasses, device):\n",
    "    model = vgg16(weights=None)\n",
    "    num_features = model.classifier[6].in_features\n",
    "    model.classifier[6] = torch.nn.Linear(num_features, nClasses)\n",
    "    model = model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8549f110",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, criterion, optimizer, device='cpu'):\n",
    "    model.train()\n",
    "    preds = []\n",
    "    targets = []\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    for imagepath, labels, inputs in train_loader:\n",
    "        labels, inputs = labels.to(device), inputs.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(inputs)\n",
    "        loss = criterion(out, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, pred = torch.max(out, 1)\n",
    "        preds.extend(pred.cpu().numpy())\n",
    "        targets.extend(labels.cpu().numpy())\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    train_loss = epoch_loss / len(train_loader)\n",
    "    acc = accuracy_score(targets, preds)\n",
    "    f1 = f1_score(targets, preds, average='macro')\n",
    "\n",
    "    return train_loss, acc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2576346e-5508-4d17-bc2b-5b4b99c553a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, criterion, device='cpu'):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    top5preds = []\n",
    "    imagepaths = []\n",
    "    targets = []\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imagepath, labels, inputs in test_loader:\n",
    "            \n",
    "            labels, inputs = labels.to(device), inputs.to(device)\n",
    "            out = model(inputs)\n",
    "            loss = criterion(out, labels)\n",
    "            _, pred = torch.max(out, 1)\n",
    "            preds.extend(pred.cpu().numpy())\n",
    "            top5pred = torch.topk(out, 5)\n",
    "            top5preds.extend(top5pred.indices.cpu().numpy())\n",
    "            imagepaths.extend(list(imagepath))\n",
    "            targets.extend(labels.cpu().numpy())\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "    val_loss = epoch_loss / len(test_loader)\n",
    "    acc = accuracy_score(targets, preds)\n",
    "    f1 = f1_score(targets, preds, average='macro')\n",
    "\n",
    "    label_in_top5preds = np.any(top5preds == np.array(targets)[:, None], axis=1)\n",
    "    top5_acc = np.mean(label_in_top5preds)\n",
    "    \n",
    "    return val_loss, acc, f1, top5_acc, top5preds, imagepaths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d58a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval(train_data, val_data, nClasses, batch_size, num_epochs, lr=0.001, weight_decay=0, device='cpu'):\n",
    "    train_scores = []\n",
    "    val_scores = []\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    best_score = 0.0\n",
    "    best_top5_acc = 0.0\n",
    "    best_model = None\n",
    "    \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size)\n",
    "    val_loader = DataLoader(val_data, batch_size=batch_size)\n",
    "\n",
    "    model = new_vit_b_16(nClasses, device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        start_time = time.time()\n",
    "        print(f'epoch {epoch}')\n",
    "        # Train\n",
    "        train_loss, train_acc, train_f1 = train_model(model, train_loader, criterion, optimizer, device)\n",
    "        print(f'train loss: {train_loss}, train accuracy: {train_acc}, train f1score: {train_f1}')\n",
    "        \n",
    "        # Eval\n",
    "        val_loss, val_acc, val_f1, top5_acc, _, _ = evaluate_model(model, val_loader, criterion, device)\n",
    "        print(f'val loss: {val_loss}, val accuracy: {val_acc}, val f1score: {val_f1}, training time: {time.time() - start_time}')\n",
    "        \n",
    "        if val_f1 > best_score:\n",
    "            best_score = val_f1\n",
    "            best_model = model\n",
    "            best_top5_acc = top5_acc\n",
    "            \n",
    "        train_losses.append(train_loss)\n",
    "        valid_losses.append(val_loss)\n",
    "        train_scores.append(train_f1)\n",
    "        val_scores.append(val_f1)\n",
    "\n",
    "    return train_losses, valid_losses, train_scores, val_scores, best_score, best_model, best_top5_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c763150",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4564913e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "batch_sizes = [32]\n",
    "learning_rate = [0.0005]\n",
    "weight_decay = [0.0005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67db87a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_train_losses = []\n",
    "best_valid_losses = []\n",
    "best_train_acc = [0]\n",
    "best_val_acc = [0]\n",
    "best_batch_size = 0\n",
    "best_params = {}\n",
    "best_model_tuned = None\n",
    "best_score_tuned = 0.0\n",
    "best_top5_acc_tuned = 0.0\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    for lr in learning_rate:\n",
    "        for wd in weight_decay:\n",
    "            train_losses, valid_losses, train_acc, val_acc, best_score, best_model, best_top5_acc = train_and_eval(train_dataset, val_dataset, nClasses,\n",
    "                                                                                                  batch_size, num_epochs, lr=lr, \n",
    "                                                                                                  weight_decay=wd, device=device)\n",
    "            if best_score > best_score_tuned:\n",
    "                best_train_losses = train_losses\n",
    "                best_valid_losses = valid_losses\n",
    "                best_train_acc = train_acc\n",
    "                best_val_acc = val_acc\n",
    "                best_batch_size = batch_size\n",
    "                best_params = {\"lr\": lr, \"weight_decay\": wd}\n",
    "                best_model_tuned = best_model\n",
    "                best_score_tuned = best_score\n",
    "                best_top5_acc_tuned = best_top5_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924b9322-7fef-45e3-bd87-f6418658e97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score_tuned, best_top5_acc_tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f00f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "xrange = list(range(0, num_epochs))\n",
    "# xrange = list(range(0, num_epochs + 1, 5))\n",
    "plt.plot(xrange, best_train_losses, label=\"Training Loss\")\n",
    "plt.plot(xrange, best_valid_losses, label=\"Cross Validation Loss\")\n",
    "plt.title(f\"Loss Curves ({topicModel})\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17329967-9fdd-46ee-b88a-f31c76cf5d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa989df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(best_model_tuned.to('cpu'), f'./models/best_model_{topicModel}.pth')\n",
    "best_model_tuned = torch.load(f'./models/best_model_{topicModel}.pth')\n",
    "best_model_tuned = best_model_tuned.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa196022-65e9-42b6-9077-a06429360a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# topicModel, num_epochs, best_batch_size, best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4c631f-472b-4fbc-a13c-6a68fd34794c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacad6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model_tuned = best_model_tuned.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076198c5-0353-4bf5-8bcd-f1d1de00dbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "train_loss, train_acc, train_f1, train_top5_acc, train_top5preds, train_imagepaths = evaluate_model(best_model_tuned, train_loader, criterion, device=device)\n",
    "val_loss, val_acc, val_f1, val_top5_acc, val_top5preds, val_imagepaths = evaluate_model(best_model_tuned, val_loader, criterion, device=device)\n",
    "test_loss, test_acc, test_f1, test_top5_acc, test_top5preds, test_imagepaths = evaluate_model(best_model_tuned, test_loader, criterion, device=device)\n",
    "print(f'train loss: {train_loss}, train accuracy {train_acc}, train f1score {train_f1}, train top5_acc {train_top5_acc}')\n",
    "print(f'val loss: {val_loss}, val accuracy {val_acc}, val f1score {val_f1}, val top5_acc {val_top5_acc}')\n",
    "print(f'test loss: {test_loss}, test accuracy {test_acc}, test f1score {test_f1}, test top5_acc {test_top5_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d761310f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savez('./outputs/model2_trainResult_' + topicModel + '.npz', trainResult_labels=train_top5preds, trainResult_imagePath=train_imagepaths)\n",
    "# np.savez('./outputs/model2_valResult_' + topicModel + '.npz', valResult_labels=val_top5preds, valResult_imagePath=val_imagepaths)\n",
    "# np.savez('./outputs/model2_testResult_' + topicModel + '.npz', testResult_labels=test_top5preds, testResult_imagePath=test_imagepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7fc9f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_final_project",
   "language": "python",
   "name": "dl_final_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
